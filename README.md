# ğŸ§  Webpage Analyzer and Q&A Assistant

This is an intelligent assistant that analyzes any public webpage and allows you to:
- âœ… Generate a concise and structured summary of the page
- â“ Ask detailed questions about the page content
- ğŸ’¬ Get accurate answers based strictly on the website data (RAG-like behavior)
---

## ğŸš€ Features

- ğŸ”— Input any public website URL
- ğŸ§¹ Clean and extract meaningful content (ignoring scripts, navbars, etc.)
- ğŸ“ Generate a smart summary of the main text
- ğŸ’¡ Ask follow-up questions about the site
- ğŸ§  Acts like a focused RAG (Retrieval-Augmented Generation) assistant

---

## ğŸ¥ Demo Video

[Click to watch the demo on Google Drive](https://drive.google.com/file/d/1QMWz4-Kp5oVGJhXAW1jsbF-aPtrVOHFO/view?usp=drive_link)
---
## ğŸ“¦ Dependencies

This project depends on the following main Python libraries:

| Package              | Description                                      |
|----------------------|--------------------------------------------------|
| `streamlit`          | Web interface for interactive user input         |
| `openai`             | To access OpenAI's GPT models via API            |
| `beautifulsoup4`     | To parse and extract text content from webpages  |
| `requests`           | To make HTTP requests and fetch webpage content  |
| `python-dotenv`      | For loading environment variables securely       |

---
## â–¶ï¸ Run the App

streamlit run app.py
---
---
## ğŸ“ Project Structure
<pre>
â”œâ”€â”€ app.py              # Streamlit frontend
â”œâ”€â”€ summarizer.py       # Backend: parsing, summarization, QA logic
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env               
â””â”€â”€ README.md
</pre>
---

## âš™ï¸ Installation
```bash
git clone https://github.com/muhammedehab35/WEB_SCRAPE_SUM.git
cd Projects_01

# Create a virtual environment
python -m venv venv
source venv/bin/activate  # or .\venv\Scripts\activate on Windows

pip install -r requirements.txt
---
---
## ğŸ‘¤ Author
by @muhammedehab
---
---

## ğŸ“œ License
MIT


